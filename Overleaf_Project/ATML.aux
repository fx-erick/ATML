\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{british}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{tian2021understanding}
\citation{Hadsell06dimensionalityreduction}
\citation{chen2020simple}
\citation{agarwal2021contrastive}
\citation{agarwal2021contrastive}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theory and Concepts}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The $\pi $-bisimulation and Policy Similarity Metric}{2}{subsection.2.1}\protected@file@percent }
\newlabel{sec: PSM}{{2.1}{2}{The $\pi $-bisimulation and Policy Similarity Metric}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Policy Similarity Embeddings - PSEs}{2}{subsection.2.2}\protected@file@percent }
\newlabel{Gaussian Kernel}{{1}{2}{Policy Similarity Embeddings - PSEs}{equation.2.1}{}}
\newlabel{contrastive loss}{{2}{2}{Policy Similarity Embeddings - PSEs}{equation.2.2}{}}
\citation{agarwal2021contrastive}
\citation{agarwal2021contrastive}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An input pair (x,y) is first augmented and then mapped into the representation space $f$. The loss function defined in Equation \ref  {contrastive loss} is applied to a non-linear projection $z$ of this representation space. \cite  {agarwal2021contrastive} \relax }}{3}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig: Learning_Architecture}{{1}{3}{An input pair (x,y) is first augmented and then mapped into the representation space $f$. The loss function defined in Equation \ref {contrastive loss} is applied to a non-linear projection $z$ of this representation space. \cite {agarwal2021contrastive} \relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Optimal trajectories are shown for two different environments. The trajectory is a sequence of right actions interrupted by a single jump action. \cite  {agarwal2021contrastive} \relax }}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig: optimal_trajectories}{{2}{3}{Optimal trajectories are shown for two different environments. The trajectory is a sequence of right actions interrupted by a single jump action. \cite {agarwal2021contrastive} \relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments from the paper}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Jumping Task from Pixels: A Case Study}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Classification of the problem}{3}{subsection.3.2}\protected@file@percent }
\citation{lee2020network}
\citation{agarwal2021contrastive}
\citation{agarwal2021contrastive}
\citation{agarwal2021contrastive}
\citation{agarwal2021contrastive}
\bibstyle{plain}
\bibdata{citations}
\bibcite{agarwal2021contrastive}{1}
\bibcite{chen2020simple}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The table summarizes the main results of the authors, giving percentages of how many test tasks could be solved using different methods with or without data augmentation. The grid configurations are shown in Figure \ref  {fig: grid_results}. It can be observed that PSEs outperform the compared methods in most configurations except for the narrow grid without data augmentation. Also, PSEs profit substantially from data augmentation. \cite  {agarwal2021contrastive}\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig: tabular_results}{{3}{4}{The table summarizes the main results of the authors, giving percentages of how many test tasks could be solved using different methods with or without data augmentation. The grid configurations are shown in Figure \ref {fig: grid_results}. It can be observed that PSEs outperform the compared methods in most configurations except for the narrow grid without data augmentation. Also, PSEs profit substantially from data augmentation. \cite {agarwal2021contrastive}\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The red letter T shows which are the training tasks for the three grid configurations and the background colour of each tile shows the performance of PSEs accross the task configurations, which is reported as the median of 100 runs per configurations using data augmentation. Beige tiles correspond to tasks that could be solved and black tiles could not be solved. \cite  {agarwal2021contrastive}\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig: grid_results}{{4}{4}{The red letter T shows which are the training tasks for the three grid configurations and the background colour of each tile shows the performance of PSEs accross the task configurations, which is reported as the median of 100 runs per configurations using data augmentation. Beige tiles correspond to tasks that could be solved and black tiles could not be solved. \cite {agarwal2021contrastive}\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Results from the paper}{4}{subsection.3.3}\protected@file@percent }
\bibcite{Hadsell06dimensionalityreduction}{3}
\bibcite{lee2020network}{4}
\bibcite{tian2021understanding}{5}
\gdef \@abspage@last{5}
