@misc{agarwal2021contrastive,
      title={Contrastive Behavioral Similarity Embeddings for Generalization in Reinforcement Learning}, 
      author={Rishabh Agarwal and Marlos C. Machado and Pablo Samuel Castro and Marc G. Bellemare},
      year={2021},
      eprint={2101.05265},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{tian2021understanding,
      title={Understanding self-supervised Learning Dynamics without Contrastive Pairs}, 
      author={Yuandong Tian and Xinlei Chen and Surya Ganguli},
      year={2021},
      eprint={2102.06810},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{Hadsell06dimensionalityreduction,
    author = {Raia Hadsell and Sumit Chopra and Yann Lecun},
    title = {Dimensionality reduction by learning an invariant mapping},
    booktitle = {In Proc. Computer Vision and Pattern Recognition Conference (CVPR'06)},
    year = {2006},
    publisher = {IEEE Press}
}

@misc{chen2020simple,
      title={A Simple Framework for Contrastive Learning of Visual Representations}, 
      author={Ting Chen and Simon Kornblith and Mohammad Norouzi and Geoffrey Hinton},
      year={2020},
      eprint={2002.05709},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lee2020network,
      title={Network Randomization: A Simple Technique for Generalization in Deep Reinforcement Learning}, 
      author={Kimin Lee and Kibok Lee and Jinwoo Shin and Honglak Lee},
      year={2020},
      eprint={1910.05396},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{hadeep,
  title={Deep Bisimulation Dreaming: Combating Distractions with State Abstractions},
  author={Ha, Huy and Kitt, Sian Lee and Zheng, William}
}

@article{kirk2021survey,
  title={A Survey of Generalisation in Deep Reinforcement Learning},
  author={Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2111.09794},
  year={2021}
}


@InProceedings{pmlr-v119-zhang20t,
  title = 	 {Invariant Causal Prediction for Block {MDP}s},
  author =       {Zhang, Amy and Lyle, Clare and Sodhani, Shagun and Filos, Angelos and Kwiatkowska, Marta and Pineau, Joelle and Gal, Yarin and Precup, Doina},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {11214--11224},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v119/zhang20t/zhang20t.pdf},
  url = 	 {https://proceedings.mlr.press/v119/zhang20t.html},
  abstract = 	 {Generalization across environments is critical to the successful application of reinforcement learning (RL) algorithms to real-world challenges. In this work we propose a method for learning state abstractions which generalize to novel observation distributions in the multi-environment RL setting. We prove that for certain classes of environments, this approach outputs, with high probability, a state abstraction corresponding to the causal feature set with respect to the return. We give empirical evidence that analogous methods for the nonlinear setting can also attain improved generalization over single- and multi-task baselines. Lastly, we provide bounds on model generalization error in the multi-environment setting, in the process showing a connection between causal variable identification and the state abstraction framework for MDPs.}
}



